{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCkTC06fdXa1"
   },
   "source": [
    "# GRO620 - Activité procédurale 2\n",
    "\n",
    "Dans cette activité procédurale, nous allons poser les bases dufiltrage numérique d'images. Vous reconnaîtrez des éléments du filtrage numérique que vous avez vu en S4.\n",
    "\n",
    "Pour chaque question impliqant de la programmation, commencez par discuter de la procédure à suivre pour résoudre le problème. Nous validerons l'approche en classe avant de se lancer dans l'implémentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1622381700727,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "qG2kPxIedXa2",
    "outputId": "a8fc660c-fe69-484e-f135-8d6d76881251"
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPbaLAJddXa3"
   },
   "source": [
    "## 1. Caractéristiques de la lumière\n",
    "\n",
    "### Q1.1\n",
    "\n",
    "Dans cette image synthétique : \n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cd/Specular_highlight.jpg)\n",
    "\n",
    "(source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Specular_highlight.jpg))\n",
    "\n",
    "**a)** Quelle(s) partie(s) correspondent à l'illumination diffuse et les reflets spéculaires ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yFIYACqdXa3"
   },
   "source": [
    "- Illumination diffuse : *smooth shading*, ou partie de lumière reflétée après absorption qui transitionne graduellement entre les différents niveaux d'illumination (ex. : l'ombre sur les sphères);\n",
    "- Reflets spéculaires : *shiny highlight*, ou partie de lumière qui est complètement reflétée (points blancs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXkcFjFKdXa4"
   },
   "source": [
    "**b)** Quelle information est nécessaire pour déterminer les caractéristiques et emplacements exacts des sources de lumières dans cette image ? Répondez en utilisant des éléments de la *Bidirectional Reflectance Distribution Function* (BRDF)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGntKizNdXa5"
   },
   "source": [
    "- Angles d'incidence ($\\theta_i$, $\\phi_i$) \n",
    "- Angles de réflexion ($\\theta_r$, $\\phi_r$)\n",
    "- Longueur d'onde ($\\lambda$)\n",
    "\n",
    "ou\n",
    "\n",
    "- Angle d'incidence ($\\theta_i$) pour corriger le *foreshortening*\n",
    "- Direction d'incidence ($\\hat{v}_i$)\n",
    "- Direction de réflexion ($\\hat{v}_r$)\n",
    "- Normale du plan de réflexion ($\\hat{n}$)\n",
    "- Longueur d'onde ($\\lambda$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VI_Lrc3_dXa5"
   },
   "source": [
    "## 2. Encodage de l'image\n",
    "\n",
    "Pour les questions suivantes, vous aurez probablement besoin de lire la documentation de cv2.imread et matplotlib.pyplot.imshow :\n",
    "\n",
    "[imread](https://pythonexamples.org/python-opencv-read-image-cv2-imread/)\n",
    "\n",
    "[imshow](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.imshow.html)\n",
    "\n",
    "Le code suivant charge une image et l'affiche en ligne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1622382035908,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "QKcjbZbedXa5",
    "outputId": "362875c8-96b7-44b1-850b-be71ecb18926"
   },
   "outputs": [],
   "source": [
    "img_BGR = cv2.imread(\"images_doc/proc1-q3-color.jpeg\")\n",
    "plt.imshow(img_BGR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8S2GxOydXa6"
   },
   "source": [
    "(source de l'image: [PixaBay, Pexels](https://www.pexels.com/photo/apartment-architecture-block-blue-534124/))\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "**a)** Ouvrez directement l'image dans un autre logiciel (le fichier se trouve dans images_doc/proc1-q3-color.jpeg) et comparez le résultat. Que remarquez vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgXatJLqdXa7"
   },
   "source": [
    "La photo est encodée en RGB, alors que la librairie CV2 enregistre les images au format BGR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p1o1bIXdXa7"
   },
   "source": [
    "**b)** Affichez seulement le premier canal de couleurs de l'image. Pensez à analyser la composition de la matrice image que OpenCV vous retourne. Expliquez ensuite ce que vous voyez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "executionInfo": {
     "elapsed": 874,
     "status": "ok",
     "timestamp": 1622381702458,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "fdr5lkmxdXa7",
    "outputId": "4f3ca685-8274-4152-931b-513edb228fa3"
   },
   "outputs": [],
   "source": [
    "simfig, plots = plt.subplots(2,2, figsize = (12,8))\n",
    "\n",
    "plots[0][0].imshow(img_BGR)\n",
    "plots[0][1].imshow(img_BGR[:, :, 0], cmap=\"gray\") # B\n",
    "plots[1][0].imshow(img_BGR[:, :, 1], cmap=\"gray\") # G\n",
    "plots[1][1].imshow(img_BGR[:, :, 2], cmap=\"gray\") # R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ6S1DQLdXa8"
   },
   "source": [
    "**c)** Transformez maintenant l'image pour que les couleurs correspondent à ce que vous voyez en dehors de Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1622381702459,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "LHy4CazOdXa8"
   },
   "outputs": [],
   "source": [
    "# First method\n",
    "img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Second method\n",
    "b, g, r = cv2.split(img_BGR)\n",
    "img_RGB = cv2.merge([r,g,b])\n",
    "\n",
    "# Third method\n",
    "img_RGB = img_BGR.copy()\n",
    "img_RGB[:,:,0] = img_BGR[:,:,2]\n",
    "img_RGB[:,:,2] = img_BGR[:,:,0]\n",
    "\n",
    "plt.imshow(img_RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT77gNXxdXa9"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Soit cette couleur dans l'espace Y'CbCr (on suppose chaque valeur comme étant encodée sur 8 bits) :\n",
    "\n",
    "$c = [100, 150, 150]$\n",
    "\n",
    "Trouvez sa valeur équivalente dans l'espace RGB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622381702460,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "hE7zxqqCdXa9"
   },
   "outputs": [],
   "source": [
    "c = np.array([100,150,150])\n",
    "\n",
    "img_YCC = np.zeros((1,1,3), dtype=np.uint8)\n",
    "img_YCC[:] = c\n",
    "\n",
    "img_RGB = cv2.cvtColor(img_YCC, cv2.COLOR_YCrCb2RGB)\n",
    "print(img_RGB[0,0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3xaTSpYdXa-"
   },
   "source": [
    "## 3. Filtrage point à point\n",
    "\n",
    "### Q3.1\n",
    "\n",
    "Soit cette image (chargée par OpenCV et affichée par matplotlib): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1622381702907,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "8UMeBW5kdXa_",
    "outputId": "e1c2357c-7f03-459b-c97d-5d5773e9ab8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_q31_org = cv2.imread(\"images_doc/proc2-q1-dock.jpeg\")\n",
    "img_q31_rgb = cv2.cvtColor(img_q31_org, cv2.COLOR_BGR2RGB) # Équivalent de la question Q3.1.c de l'activité procédurale 1.\n",
    "plt.imshow(img_q31_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGJXZD57dXa_"
   },
   "source": [
    "(Source de l'image originale : [Vlada Karpovich, Pexels](https://www.pexels.com/photo/snow-wood-landscape-mountains-4450090/))\n",
    "\n",
    "Cette fonction affiche l'histogramme des trois composantes de l'image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 156,
     "status": "ok",
     "timestamp": 1622381703057,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "QflhwsQ0dXbA",
    "outputId": "d8deb252-31d0-4ecc-8842-816ac713d3f3"
   },
   "outputs": [],
   "source": [
    "channels = ('r','g','b')\n",
    "for i, col in enumerate(channels):\n",
    "    hist = cv2.calcHist([img_q31_rgb], [i], None, [256], [0,256])\n",
    "    plt.plot(hist,color = col)\n",
    "    plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AroW4G2zdXbA"
   },
   "source": [
    "Ajustez la plage dynamique en luminosité de l'image pour qu'elle couvre l'ensemble des valeurs possibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 181,
     "status": "ok",
     "timestamp": 1622381703230,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "sc3_u8xrdXbB",
    "outputId": "337fb345-3f22-49d0-c37a-a98b42a1a0f2"
   },
   "outputs": [],
   "source": [
    "# NOTE: On convertit d'abord en float32 dans la plage [0,1] pour\n",
    "# simplifier la manipulation des images avec des facteurs non-entiers.\n",
    "# Matplotlib détecte ceci et affichera l'image correctement.\n",
    "img_q31_f = np.float32(img_q31_rgb) / 255.0\n",
    "\n",
    "# Preserves RGB proportions\n",
    "img_q31_out = img_q31_f.copy()\n",
    "img_q31_out /= img_q31_f.max()\n",
    "\n",
    "# Maximizes color channels independently\n",
    "img_q31_max_rgb = img_q31_f.copy()\n",
    "img_q31_max_rgb[:,:,0] /= img_q31_f[:,:,0].max()\n",
    "img_q31_max_rgb[:,:,1] /= img_q31_f[:,:,1].max()\n",
    "img_q31_max_rgb[:,:,2] /= img_q31_f[:,:,2].max()\n",
    "\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,10))\n",
    "plots[0].imshow(img_q31_out)\n",
    "plots[1].imshow(img_q31_max_rgb)\n",
    "\n",
    "channels = ('r','g','b')\n",
    "simfig, plots = plt.subplots(2,1, figsize = (12,6))\n",
    "for i, col in enumerate(channels):\n",
    "    hist = cv2.calcHist([img_q31_out], [i], None, [256], [0,1])\n",
    "    plots[0].plot(hist,color = col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "for i, col in enumerate(channels):\n",
    "    hist = cv2.calcHist([img_q31_max_rgb], [i], None, [256], [0,1])\n",
    "    plots[1].plot(hist,color = col)\n",
    "    plt.xlim([0,256])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOc3K-_ydXbB"
   },
   "source": [
    "## Q3.2\n",
    "\n",
    "Soit maintenant cette image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1622381703917,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "R8RjOELadXbB",
    "outputId": "4f6ab7da-ebcc-4718-9c2a-54573a482248"
   },
   "outputs": [],
   "source": [
    "img_q32_org = cv2.imread(\"images_doc/proc2-q1-object.jpeg\")\n",
    "img_q32_rgb = cv2.cvtColor(img_q32_org, cv2.COLOR_BGR2RGB) # Équivalent de la question Q3.1.c de l'activité procédurale 1.\n",
    "plt.imshow(img_q32_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmSXJMPodXbC"
   },
   "source": [
    "Tentez de mettre en place un algorithme basé sur la luminosité permettant d'éliminer l'arrière-plan de cette image pour qu'il ne reste que l'objet en jaune sur un fond le plus noir possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1622381703924,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "idkkNWNqdXbC"
   },
   "outputs": [],
   "source": [
    "img_q32_filt = img_q32_rgb.copy()\n",
    "W = img_q32_filt.shape[1] # NOTE: L'ordre des dimensions est Y puis X (\"row-major\")\n",
    "H = img_q32_filt.shape[0]\n",
    "\n",
    "threshold = 180\n",
    "\n",
    "# First method - max of any channel\n",
    "img_01 = img_q32_rgb.copy()\n",
    "for i in range(W):\n",
    "    for j in range(H):\n",
    "        if img_01[i,j].max() < threshold:\n",
    "            img_01[i,j] = np.zeros(3)\n",
    "            \n",
    "# Second method - mean of channels\n",
    "img_02 = img_q32_rgb.copy()\n",
    "for i in range(W):\n",
    "    for j in range(H):\n",
    "        if img_02[i,j].mean() < threshold:\n",
    "            img_02[i,j] = np.zeros(3)\n",
    "            \n",
    "# Third method - gray colormap\n",
    "img_03 = img_q32_rgb.copy()\n",
    "img_03 = cv2.cvtColor(img_03, cv2.COLOR_RGB2GRAY)\n",
    "_, img_03 = cv2.threshold(img_03, threshold, 255, cv2.THRESH_BINARY)\n",
    "            \n",
    "# Fourth method - Otsu method\n",
    "img_04 = img_q32_rgb.copy()\n",
    "img_04 = cv2.cvtColor(img_04, cv2.COLOR_BGR2GRAY)\n",
    "_, img_04 = cv2.threshold(img_04, threshold, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "img_04 = cv2.findContours(img_04, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "img_04 = sorted(img_04, key=cv2.contourArea)\n",
    "for i in img_04:\n",
    "    if cv2.contourArea(i) > 250: break\n",
    "\n",
    "mask = np.zeros(img_q32_rgb.shape[:2], np.uint8)\n",
    "cv2.drawContours(mask, [i],-1, 255, -1)\n",
    "img_04 = cv2.bitwise_and(img_q32_rgb, img_q32_rgb, mask=mask)\n",
    "\n",
    "# Fifth method - HSV\n",
    "img_05 = img_q32_rgb.copy()\n",
    "img_05 = cv2.cvtColor(img_05, cv2.COLOR_RGB2HSV)\n",
    "v_value = img_05[100,100,2]\n",
    "lower = np.array([0,0,v_value], np.uint8)\n",
    "upper = np.array([threshold, 255, 255], np.uint8)\n",
    "mask = cv2.inRange(img_05, lower, upper)\n",
    "img_05 = cv2.bitwise_and(img_q32_rgb, img_q32_rgb, mask=mask)\n",
    "\n",
    "if not os.path.exists('./output'):\n",
    "    os.makedirs('./output')\n",
    "    \n",
    "simfig, plots = plt.subplots(1,5, figsize = (16,10))\n",
    "plots[0].imshow(img_01)\n",
    "plots[1].imshow(img_02)\n",
    "plots[2].imshow(img_03, cmap=\"gray\")\n",
    "plots[3].imshow(img_04)\n",
    "plots[4].imshow(img_05)\n",
    "simfig.savefig('output/q32.pdf', dpi=300)\n",
    "\n",
    "cv2.imwrite('output/q32_max.jpg', cv2.cvtColor(img_01, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('output/q32_mean.jpg', cv2.cvtColor(img_02, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('output/q32_gray.jpg', cv2.cvtColor(img_03, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('output/q32_otsu.jpg', cv2.cvtColor(img_04, cv2.COLOR_RGB2BGR))\n",
    "cv2.imwrite('output/q32_hsv.jpg', cv2.cvtColor(img_05, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CByUCiAUdXbC"
   },
   "source": [
    "## 4. Filtrage linéaire\n",
    "\n",
    "### Q4.1 \n",
    "\n",
    "Soit l'image suivante ainsi que sa transformée de Fourier :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1622381704288,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "hsQ_TgmPdXbD",
    "outputId": "41d9d9f0-2312-471f-c434-d5cb2723612f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_q4_org  = cv2.imread(\"images_doc/proc2-q2-texture.jpeg\")\n",
    "img_q4_mono = np.float32(cv2.cvtColor(img_q4_org, cv2.COLOR_BGR2GRAY)) / 255.0\n",
    "\n",
    "def get_fft_mag(img):\n",
    "    img_fft = np.fft.fft2(img)\n",
    "    img_fft = np.fft.fftshift(img_fft)\n",
    "    img_fft = 20*np.log(np.abs(img_fft))\n",
    "    return img_fft\n",
    "    \n",
    "img_q4_mono_fft = get_fft_mag(img_q4_mono)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img_q4_mono, cmap=\"gray\")\n",
    "plt.subplot(122),plt.imshow(img_q4_mono_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCs7RSltdXbD"
   },
   "source": [
    "(Source de l'image originale : [Hoang Le, Pexels](https://www.pexels.com/photo/black-and-white-black-and-white-pattern-rough-978462/)).\n",
    "\n",
    "**a)** Filtrez cette image à l'aide d'une convolution de façon à ce que la valeur de chaque pixel soit la valeur moyenne de ses voisins dans un carré de 15x15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622381704290,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "x0V1T6EZdXbE"
   },
   "outputs": [],
   "source": [
    "dim = 15\n",
    "filter_kernel = np.ones((dim,dim),np.float32)/dim**2\n",
    "img_q4_conv = cv2.filter2D(img_q4_mono,-1,filter_kernel)\n",
    "img_q4_conv_fft = get_fft_mag(img_q4_conv)\n",
    "\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,6))\n",
    "plots[0].imshow(img_q4_mono, cmap=\"gray\")\n",
    "plots[1].imshow(img_q4_mono_fft)\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,6))\n",
    "plots[0].imshow(img_q4_conv, cmap=\"gray\")\n",
    "plots[1].imshow(img_q4_conv_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omvSPfAQdXbE"
   },
   "source": [
    "**b)** Comparez le résultat avec celui de la fonction cv2.GaussianBlur() avec un noyau de convolution de la même taille."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1622381704869,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "eDPy-hAIdXbF",
    "outputId": "94538434-8c1c-491c-a680-adb7134ece97"
   },
   "outputs": [],
   "source": [
    "img_q4_blur = cv2.GaussianBlur(img_q4_mono, (dim,dim), 0)\n",
    "img_q4_blur_fft = get_fft_mag(img_q4_blur)\n",
    "\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,6))\n",
    "plots[0].imshow(img_q4_mono, cmap=\"gray\")\n",
    "plots[1].imshow(img_q4_mono_fft)\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,6))\n",
    "plots[0].imshow(img_q4_conv, cmap=\"gray\")\n",
    "plots[1].imshow(img_q4_conv_fft)\n",
    "simfig, plots = plt.subplots(1,2, figsize = (10,6))\n",
    "plots[0].imshow(img_q4_blur, cmap=\"gray\")\n",
    "plots[1].imshow(img_q4_blur_fft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I12xqvM8dXbG"
   },
   "source": [
    "**c)** Comment expliquez-vous la différence ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLrrFz_GdXbH"
   },
   "source": [
    "La moyenne mobile accentue certains pixels au lieu de les rendre diffus, ce qui crée de l'*aliasing* à l'intérieur de l'image. Ce n'est pas le cas avec la gaussienne, qui elle permet d'éviter l'accentuation grâce à sa distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMO7I2QIdXbI"
   },
   "source": [
    "### Q4.2\n",
    "\n",
    "Utilisez un filtre linéaire pour extraire les contours de l'image fournie en Q3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622381704869,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "qe-Xt4RfdXbJ"
   },
   "outputs": [],
   "source": [
    "# First method\n",
    "img_q32_contour = img_q32_rgb.copy()\n",
    "filter_kernel = np.array([[1,0,-1],[0,0,0],[-1,0,1]])\n",
    "img_q32_contour = cv2.cvtColor(img_q32_contour, cv2.COLOR_RGB2GRAY)\n",
    "img_q32_contour = cv2.filter2D(img_q32_contour,-1,filter_kernel)\n",
    "\n",
    "# Second method\n",
    "img_q32_contour = img_q32_rgb.copy()\n",
    "dim = 15\n",
    "minVal = 150\n",
    "maxVal = 200\n",
    "img_q32_contour = cv2.GaussianBlur(img_q32_contour, (15,15), 0)\n",
    "img_q32_contour = cv2.Canny(img_q32_contour, minVal, maxVal)\n",
    "\n",
    "# Third method\n",
    "# ./input/q42_Sobel.png\n",
    "\n",
    "# Fourth method\n",
    "# ./input/q42_filter2D.png\n",
    "\n",
    "plt.imshow(img_q32_contour, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KB_XL5kodXbN"
   },
   "source": [
    "## 5. Filtrage morphologique et chaîne de traitement\n",
    "\n",
    "### Q5.1 \n",
    "\n",
    "À partir de l'image de la question Q1.1, combinez les filtres vus plus tôt pour ne conserver que le contour de l'objet de la figure (donc sans bruit de fond)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1622381705068,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "nvpgC4JQdXbO"
   },
   "outputs": [],
   "source": [
    "img_BGR = cv2.imread(\"images_doc/proc1-q3-color.jpeg\")\n",
    "img_RGB = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "dim = 15\n",
    "minVal = 0\n",
    "maxVal = 150\n",
    "img_RGB = cv2.GaussianBlur(img_RGB, (15,15), 0)\n",
    "img_RGB = cv2.Canny(img_RGB, minVal, maxVal)\n",
    "\n",
    "plt.imshow(img_RGB, cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "proc_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

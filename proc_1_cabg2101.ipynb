{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kh7ikCw1dWx5"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "  table {margin-left: 0!important; width: 75%;}\n",
    "</style>\n",
    "<style>\n",
    "  td {font-size: 14px;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRO620 - Activité procédurale 1\n",
    "\n",
    "Dans cette activité, nous allons principalement travailler sur les éléments nécessaires pour capter une image numériquement, les transformations entre repères 2D et 3D, et l'encodage numérique de la couleur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45339,
     "status": "ok",
     "timestamp": 1622381462155,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "pC6BnG_3dWyA",
    "outputId": "4486fcd9-17b2-4018-e963-c0b64774adcc"
   },
   "outputs": [],
   "source": [
    "# Préambule\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1xSdXoMdWyB"
   },
   "source": [
    "## Acquisition\n",
    "\n",
    "### Q1.1\n",
    "\n",
    "À partir de la figure 2.23 du livre de référence, décrivez en une phrase le rôle de chacune des étapes de la chaîne d'acquisition d'images numériques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPRDNqrrdWyB"
   },
   "source": [
    "| Acronym | Definition                                     |\n",
    "| :------ | :--------------------------------------------- |\n",
    "| A/D     | Analog-to-Digital                              |\n",
    "| CCD     | Charge-Coupled Device                          |\n",
    "| CMOS    | Complementary Metal–Oxide–Semiconductor        |\n",
    "| DSP     | Digital Signal Processing                      |\n",
    "| ISO     | International Organization for Standardization |\n",
    "\n",
    "#### Camera Body\n",
    "\n",
    "- Optics: Focaliser la lumière sur le capteur.\n",
    "- Aperture: Contrôler la quantité de lumière entrante.\n",
    "- Shutter: Contrôler la durée d'exposition de la lumière sur le capteur.\n",
    "\n",
    "#### Sensor Chip\n",
    "\n",
    "- Sensor (CCD/CMOS): Capter la lumière.\n",
    "- Gain (ISO): Amplifier le signal analogique (sensibilité de détection).\n",
    "- A/D Converter: Convertir le signal analogique en signal numérique.\n",
    "\n",
    "#### DSP\n",
    "\n",
    "- Demosaic: Reconstruction de l'image couleur avec les échantillons provenant du capteur. On peut aussi parler d'interpolation.\n",
    "- Sharpen: Rehausser les différences en augmentant les hautes fréquences (filtre).\n",
    "- White Balance: Modifier l'éclairage ou la température de la photo.\n",
    "- Gamma / Curve Correction: Modification de la luminance avec une loi de puissance.\n",
    "- Compression: Encoder l'information de l'image de façon à réduire le nombre de bits requis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zdxhihn2dWyB"
   },
   "source": [
    "### Q1.2\n",
    "\n",
    "Quelle est la différence entre paramètres intrinsèques et extrinsèques d'une caméra ? Décrivez chaque type en une phrase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiFuS6rPdWyC"
   },
   "source": [
    "- Intrinsèque: propre à la caméra, interne (ex.: la taille du capteur).\n",
    "- Extrinsèque: se rapporte à la caméra par rapport à son environnement, externe (ex.: la position de la caméra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FWZECptdWyC"
   },
   "source": [
    "### Q1.3\n",
    "\n",
    "Soit la configuration intrinsèque d'une caméra représentée par la matrice $K$ :\n",
    "\n",
    "$$\n",
    "K = \\begin{bmatrix} \n",
    " 620 &   0 & 1024 \\\\ \n",
    "   0 & 620 &  512 \\\\ \n",
    "   0 &   0 &    1 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Le capteur de cette caméra a une taille de 30 mm x 15 mm.\n",
    "\n",
    "Pouvez-vous estimer la distance focale en mm de la lentille de cette caméra à partir de la matrice $K$ ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcfUfXCCdWyC"
   },
   "outputs": [],
   "source": [
    "# Focal length:  620px\n",
    "# Half-width:   1024px or 30mm\n",
    "# Half-height:   512px 04 15mm\n",
    "\n",
    "K = np.array([[620.,   0., 1024.],\n",
    "              [  0., 620.,  512.],\n",
    "              [  0.,   0.,    1.]\n",
    "])\n",
    "\n",
    "f = 30*K[0,0]/(2*K[0,2])\n",
    "print(f\"Distance focale: {f:.3f} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quJcFsPbdWyD"
   },
   "source": [
    "### Q1.4\n",
    "\n",
    "Dans le cadre de cet APP, nous considérons les caméras comme étant idéales, c'est-à-dire qu'on peut obtenir leurs caractéristiques intrinsèques et extrinsèques à partir de quelques paramètres seulement.\n",
    "\n",
    "**a)** Qu'est-ce qui rend les vraies caméras non-idéales ? Nommez des facteurs autant pour les caractéristiques intrinsèques que extrinsèques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Erl2fPTidWyD"
   },
   "source": [
    "- *Skew*, ou un mauvais alignement entre l'axe optique et la normale du capteur\n",
    "- Distorsion radiale (ex.: *pincushion* ou *barrel*)\n",
    "- Tolérances durant le processus de fabrication\n",
    "- Position de la caméra par rapport au repère global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sfg46RtdWyD"
   },
   "source": [
    "**b)** Que doit on faire pour obtenir les caractéristiques d'une caméra non-idéale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bezo06eCdWyE"
   },
   "source": [
    "Une calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhFn190TftCu"
   },
   "source": [
    "### Q1.5\n",
    "\n",
    "**a)** Pourquoi deux appareils de capture peuvent produire des valeurs RGB différentes d'une même couleur ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4LmStT2f6C1"
   },
   "source": [
    "Suffit qu'un seul aspect varie dans la chaîne d'acquisition en amont pour produire des couleurs numériques différentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obSsXTc8f5XM"
   },
   "source": [
    "**b)** Que peut-on faire pour comparer numériquement des couleurs provenant de deux capteurs différents ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZ629ialf4VV"
   },
   "source": [
    "*Mapping* des couleurs vers un espace commun XYZ (chaque couleur est sur un spectre de 0 à 1). On peut aussi utiliser un espace L\\*a\\*b\\*, ou la distance euclidienne varie selon la perception de l'oeil humain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKQOpwTVdWyE"
   },
   "source": [
    "## Repères et coordonnées\n",
    "\n",
    "### Q2.1\n",
    "\n",
    "Supposons ces 2 repères :\n",
    "\n",
    "![](images_doc/proc1-q2_1-frames.png)\n",
    "\n",
    "**a)** Trouvez la matrice homogène permettant de transformer un point du repère $\\{1\\}$ au repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jULxdVBsdWyE",
    "outputId": "630316fc-4340-46fa-aa1f-54f653075553"
   },
   "outputs": [],
   "source": [
    "T_10 = np.identity(4) # Génère une matrice identité 4x4\n",
    "\n",
    "T_10 = np.array([[0,1,0,240],[1,0,0,80],[0,0,-1,120],[0,0,0,1]])\n",
    "\n",
    "print(\"T_10:\\n\", T_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJIOwDUPdWyF"
   },
   "source": [
    "**b)** Trouvez maintenant la transformation inverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LH35FSWqdWyG"
   },
   "outputs": [],
   "source": [
    "T_01 = np.identity(4)\n",
    "T_01 = np.linalg.inv(T_10)\n",
    "print(\"T_01:\\n\", T_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L2ximr9WdWyG"
   },
   "source": [
    "**c)** Soit le point $p_0 = [8, 5, 1]^T$, un point dans le repère $\\{0\\}$. Trouvez $p_1$, ses coordonnées dans le repère $\\{1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nj0k5hkLdWyG"
   },
   "outputs": [],
   "source": [
    "p_0 = [8, 5, 1]\n",
    "p_1 = [0, 0, 0]\n",
    "\n",
    "p_0_h = [8,5,1,1]\n",
    "p_1_h = T_01 @ p_0_h\n",
    "\n",
    "p_1 = [k for k in p_1_h[0:-1]]\n",
    "print(p_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPkWLvBydWyH"
   },
   "source": [
    "### Q2.2\n",
    "\n",
    "Supposons maintenant que le repère $\\{1\\}$ représente une caméra avec les caractéristiques intrinsèques $K$ de la question Q1.3.\n",
    "\n",
    "**a)** Trouvez la matrice de projection P complète permettant de projeter un point $p$ décrit dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6XhSj3FRdWyH",
    "outputId": "ab32f10e-8b2c-4cea-ed94-5ec725bbe94c"
   },
   "outputs": [],
   "source": [
    "# print(K) # Si vous n'avez pas réutilisé la variable K, elle aura toujours la même valeur qu'à la question Q1.3.\n",
    "\n",
    "R = np.array([T_01[0][0:-1],T_01[1][0:-1],T_01[2][0:-1]])\n",
    "t = np.array(T_01.T[-1][0:-1])\n",
    "\n",
    "Kt = np.zeros([4,4])\n",
    "Kt[0:-1,0:-1] = K\n",
    "Kt[-1,-1] = 1\n",
    "\n",
    "Rt = np.zeros([4,4])\n",
    "Rt[0:-1,0:-1] = R\n",
    "Rt[0:-1,-1] = t\n",
    "Rt[-1,-1] = 1\n",
    "\n",
    "Pt = Kt @ Rt\n",
    "print(Pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UEWupgIdWyI"
   },
   "source": [
    "**b)** Soit le point $p_0 = [0.250, 0.010, 0.000]$. Trouvez le point $x_s$, les coordonnées du point $p_0$ perçu par la caméra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On veut trouver ses coordonnées dans l'image. On peut utiliser l'équation (2.65) du livre. Pour cela, il faut d'abord bâtir Pt ($\\tilde{P}$), qui dépend également de K. Rappel des équations :\n",
    "\n",
    "\n",
    "$$P  = K \\left[R \\middle| T\\right]$$\n",
    "\n",
    "$$\\tilde{P} = \\tilde{K} E$$\n",
    "\n",
    "$$x_s \\sim \\tilde{P} \\bar{p_w}$$\n",
    "\n",
    "$$x_s = \\left(X_s, Y_s, 1, d\\right)$$\n",
    "\n",
    "$$d = \\frac{1}{z}$$\n",
    "\n",
    "Dans notre cas, $E$ correspond à $T_{01}$, car on souhaite passer du repère global à celui de la caméra, $p_w$ est donc $p_0$ et $x_s$ continendra les coordonnées normalisées dans l'image.\n",
    "\n",
    "$d$ correspond à la disparité, ou $1/z$, où $z$ et la distance du point dans le repère de la caméra (donc en Z, où Z augmente avec la distance).\n",
    "\n",
    "Nous pouvons maintenant bâtir les matrices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WryXyIycdWyI"
   },
   "outputs": [],
   "source": [
    "p_0 = np.array([0.250, 0.010, 0.000])\n",
    "\n",
    "p_0_h = np.ones(4)\n",
    "p_0_h[0:-1] = p_0\n",
    "\n",
    "xs = Pt.dot(p_0_h)\n",
    "xs /= xs[2]\n",
    "print(xs[0:-1])\n",
    "print(f\"Camera / image distance: {1/xs[-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on arrondit, on obtient (611, -727), ce qui donne un point en dehors du capteur. Le point $p_0$ est donc hors du champ de vision. En effet, les coordonnées sont référencées au coint supérieur gauche de l'image.\n",
    "\n",
    "Si on regarde les repères, notre point est situé sur l'axe négatif en Y, ce qui veut dire qu'il est trop \"en haut\" de la caméra. Sur le repère ${0}$, ceci correspond à un point probablement trop près du référentiel sur l'axe des X. Nous allons donc rapprocher le point sur l'axe des X pour tenter de trouver une coordonnée image plus intéressante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1w = np.array([300,0.010,0.001,1])\n",
    "x1_s_p = Pt @ p1w\n",
    "x1_s = x1_s_p / x1_s_p[2]\n",
    "print(x1_s[0:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpa--SomdWyY"
   },
   "source": [
    "## Reprojection 2D à 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVHRnJsIdWyY"
   },
   "source": [
    "### Q3.1\n",
    "\n",
    "Supposons que le plan XY du repère $\\{0\\}$ est un convoyeur. Quelle serait sa largeur maximale (mesurée sur l'axe Y) si on souhaite que la caméra la capte au complet dans son image ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2WqHjEONdWyZ"
   },
   "outputs": [],
   "source": [
    "l_conv = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jk6xchjCdWyZ"
   },
   "source": [
    "### Q3.2\n",
    "\n",
    "Soit le point $x_s = [120, 200]$, un point dans l'image perçu par la caméra décrite plus haut. On suppose que le point perçu se trouve sur le plan XY du repère $\\{0\\}$. Trouvez les coordonnées du point $p_0$ qui correspond à ce même point dans le repère $\\{0\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GYiNDm-BdWya"
   },
   "outputs": [],
   "source": [
    "x_s = np.array([120,200, 1, 1/120])\n",
    "\n",
    "Pt_inv = np.linalg.inv(Pt)\n",
    "print(\"Pt_inv:\\n:\", Pt_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Attention: ici, on ne peut pas simplement transposer comme si c'était un repère)\n",
    "\n",
    "En inversant, on repasse d'un système en pixels à un en mm. Or, on ne peut pas tout de suite multiplier $\\tilde{P}^{-1}$ et un vecteur de coordonnées en pixels. On se rappelle que cette matrice ne manipule que les coordonnées normalisées. Il faut donc remultiplier par $z$, ou diviser par $d$ (ce qui correspond à diviser par $1/z$). On peut s'en convaincre avec le point précédent :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rp = x_s / x_s[3] # rp pour \"reprojection\"\n",
    "print(x_rp) # Devrait corresponde à x_s_p\n",
    "p_0_rp = np.matmul(Pt_inv, x_rp)\n",
    "print(p_0_rp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient donc un point franchement vers Y- (ce qui correspond à la gauche de l'image) et à mi-chemin entre les deux repères en X, ce qui a du sens compte tenu des coordonnées de l'image."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "proc_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

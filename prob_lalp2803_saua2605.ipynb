{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgQOnFaMafaj"
   },
   "source": [
    "# GRO620 - Problématique\n",
    "\n",
    "Voici le fichier de départ de la problématique. Si tout a été installé correctement, vous devriez voir apparaître la première image (DSCF8010.jpeg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27783,
     "status": "ok",
     "timestamp": 1622380668682,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "-VU4KSYoafal",
    "outputId": "d93e99f5-cf28-49fb-b7d9-eec44e69e0d8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print(\"GRO620 - Problématique\")\n",
    "print(\"OpenCV version\", cv2.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 260,
     "status": "ok",
     "timestamp": 1622381205611,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "nTsbHtmDbQ7Y",
    "outputId": "0d51d195-b4f0-4523-997e-b50f6b71c90f"
   },
   "outputs": [],
   "source": [
    "## Si vous utilisez Google Colab, vous devez d'abord monter votre Google Drive\n",
    "## où se trouve vos données. \n",
    "## Commentez les trois lignes suivantes en ajustant le chemin vers votre propre\n",
    "## dossier :\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# %cd /content/gdrive/MyDrive/gro620-e21\n",
    "\n",
    "## Pour retrouver le chemin depuis Jupyter, vous pouvez utiliser ceci :\n",
    "# !ls /content/gdrive/MyDrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 228,
     "status": "ok",
     "timestamp": 1622381208906,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "siu9fo1oafam",
    "outputId": "4c8a7395-f492-4906-e413-c5d2767b3a91"
   },
   "outputs": [],
   "source": [
    "images_fn = os.listdir(\"photos_prob/\")\n",
    "print(\"%i photo(s) à traiter\"%(len(images_fn)))\n",
    "if (len(images_fn) == 0):\n",
    "    print(\"ERREUR! Vérifiez que vous avez bien un dossier photos_prob au même endroit que ce calepin.\")\n",
    "    \n",
    "images = []\n",
    "\n",
    "for f in images_fn:\n",
    "    img = cv2.imread(os.path.join(\"photos_prob/\", f))\n",
    "    images.append(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification du problème \n",
    "\n",
    "\n",
    "Pour la problématique, l'employeur demande à faire une preuve de concept pour trier de la quincaillerie. Le mandat est de faire la séparation et l'analyse des différentes vis qui se situe sur un convoyeur.\n",
    "\n",
    "Pour cette problématique, il y a de nombreux problèmes a résoudre. Pour commencer, il y a différente grandeur de vis, il va donc être important de différencier la taille de chacune des vis présentes. Il faut aussi identifier leur position et leur angle sur le convoyeur.\n",
    "\n",
    "Pour le convoyeur, sa surface n'est pas parfaite, il y a donc des imperfections dans la fond de l'image prise par la caméra. De plus, le convoyeur possède des encoches directement sur sa surface, il faudra donc que la solution prenne en considération ces deux détails pour bien isoler les vis dans l'image.\n",
    "\n",
    "Pour la caméra, elle est centré avec le convoyeur et prend des images en couleur vu de haut. L'analyse est effectué en jouant sur les paramètres des pixels de l'image. Pour trouver l'emplacement des vis sur la convoyeur, il faudra s'assurer de convertir les positions obtenues après analyse pour les mettre dans le repère du convoyeur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wkVkmnfbNEG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = 0.023 #Distance focale (m)\n",
    "res = np.array([640,427]) #Résolution de la caméra (pixel)\n",
    "capt = np.array([0.0234, 0.0156]) #Dimension du capteur (m)\n",
    "\n",
    "fx = f*res[0]/capt[0]\n",
    "fy = f*res[1]/capt[1]\n",
    "\n",
    "###Matrice de transformation convoyeur à caméra###\n",
    "Tc = np.array([[1,0,0,0.5],\n",
    "               [0,-1,0,0.2],\n",
    "               [0,0,-1,0.282],\n",
    "               [0,0,0,1]])\n",
    "Tc_inv = np.linalg.inv(Tc)\n",
    "\n",
    "###Matrice de calibration pour la caméra###\n",
    "K = np.array([[fx, 0., res[0]/2],\n",
    "              [0., fy, res[1]/2],\n",
    "              [0., 0., 1.]])\n",
    "\n",
    "K_p = np.identity(4)\n",
    "K_p[:3, :3] = K\n",
    "\n",
    "###Matrice de la caméra###\n",
    "P = np.dot(K_p,Tc_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtcVfNIbafam"
   },
   "source": [
    "Affichons maintenant la première image à traiter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 896,
     "status": "ok",
     "timestamp": 1622381212654,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "ssktgviGafan",
    "outputId": "8a8ccb4a-44e0-416b-a07f-300d6175714d"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procédure de résolution\n",
    "\n",
    "Pour isoler les vis sur le convoyeur, il faut enlever les détails du convoyeur, c'est-à-dire le fond de l'image qui est rugeux. Pour ce faire, il faudra probablement utiliser un filtre qui enlevera les hautes-fréquences en prennant la valeur des couleurs de ses voisins. Le résultat devrait amener l'image avec moins de détails et un peu embrouillé.  \n",
    "\n",
    "Le fond peut être retiré en fonction de l'opacité, car on cherche seulement les vis. Le résultat souhaité est d'avoir seulement les vis sur l'image.\n",
    "\n",
    "Par la suite, il faut s'assurer d'avoir la bonne forme de vis, semblable à l'image de départ. Certaines transformées des pixels isolées peuvent être utilisées pour modifier l'apparence des vis.\n",
    "\n",
    "Une fois les vis bien isolées et dimensionnées, une méthode pour trouver les contours peut être utilisée. Ayant les contours, les vis peuvent être encadrées avec un rectangle pour trouver la longueur, l'angle et le centre de la vis.\n",
    "\n",
    "Il faut faire attention aux abérations, c'est-à-dire les fentes du convoyeur et les vis cachées sur les côtés. Il faut mettre une vérification pour trouver si le contour trouvé est vraiment une vis.\n",
    "\n",
    "Finalement, il faut convertir les données de la vis du repère de la caméra à celui du convoyeur. Il faut ajouter une composante en z, car l'analyse de l'image donne des coordonnés en 2D. Les données sont enregistrées en csv dans un tableau contenant l'identifiant, le type, la position en X, Y, Z et l'angle en radians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typeVis(size):\n",
    "    \n",
    "    itemLength = np.abs(size).max()\n",
    "    \n",
    "    if itemLength < 100: itemType = \"courte\"\n",
    "    else: itemType = \"longue\"\n",
    "    \n",
    "    return str(itemType) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repositionnementAngle(width,height,angle):\n",
    "    \n",
    "    if (width < height):\n",
    "        angle -= 90\n",
    "\n",
    "    return int(angle)*-np.pi/180\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mise en œuvre du pipeline\n",
    "\n",
    "La première étape est de convertir l'image en monochrome pour faciliter le travail de cette dernière.\n",
    "\n",
    "La deuxième étape est de réduire les détails, causés par les hautes-fréquences, avec un filtre linéaire de type gaussien. Cette étape permet d'embrouiller l'image et ainsi retirer les petits détails qui influenceraient les prochaines étapes.\n",
    "\n",
    "La troisième étape est d'utiliser un seuillage (threshold) pour enlever le fond de l'image et ainsi isoler les vis. Ceci va permet de trouver les contours plus facilement en retirant toutes les sections qui ne sont pas à analyser. Selon les valeurs choisies, les vis peuvent être affecté par le seuillage.\n",
    "\n",
    "La quatrième étape est d'ajuster les vis isolées par le seuillage, car les limites du seuillage ne sélectionne pas la vis en entier à cause des différentes intensités de lumière. Les vis se retrouvent alors amincis et l'opération morphologique `dilate` doit être utilisé pour rétablir leur taille.\n",
    "\n",
    "La cinquième étape est d'utiliser un filtre Canny qui détecte les points situés sur le contour des objets et fait une approximation du contour de l'objet.\n",
    "\n",
    "La sixième étape est d'utiliser `findContours` pour sélectionner les points trouvés par la dernière étape et les enregistrer.\n",
    "\n",
    "La septième étape est de dessiner les contours sur l'image originelle. L'identification du point central de la vis est aussi ajouté. En plus, l'utilisation de la fonction `minAreaRect` permet d'encadrer les vis et ainsi trouver leurs longueurs et leurs orientations.\n",
    "\n",
    "La huitième étape est de trouver et transformer les données de chaque vis. Pour le type de vis, une vérification de la plus grande dimension de l'encadré permet de vérifier sa longueur. Pour trouver l'angle, il faut faire une conversion selon ce que la fonction `minAreaRect` retourne, car elle donne l'angle la plus proche de zéro ne prenant pas en compte l'orientation du rectangle. Pour la position centrale, il faut faire une conversion du repère de la caméra, en pixel et en 2D, à celui du convoyeur, en mètre et en 3D. Pour ce faire, il faut utiliser la matrice de la caméra qui permet de transformer les points du repère du convoyeur à celui de la caméra. Cependant, il faut s'assurer de faire une projection sur le plan XY pour ajouter cette composante au point en 2D. Il faut aussi s'assurer que le quatrième terme a une valeur de un en divisant la position par ce dernier.\n",
    "\n",
    "La dernière étape est de sauvegarder les données sous la forme d'un tableau dans un fichier csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "aborted",
     "timestamp": 1622380530547,
     "user": {
      "displayName": "François Ferland",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgF2Or95FbA-4pBmWOKA7jS0MHVh9HZkxsXcGWI=s64",
      "userId": "06573522356862301710"
     },
     "user_tz": 240
    },
    "id": "L7AtES9Dafan"
   },
   "outputs": [],
   "source": [
    "######Décommentez les lignes plt pour voir les images de chaque section#######\n",
    "def isolationDesContours(image):\n",
    "    img = image.copy()\n",
    "\n",
    "    ###Mettre en monochrome###\n",
    "    img_mono = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    ###Gaussian pour réduire les détails###\n",
    "    img_gaus = cv2.GaussianBlur(img_mono,(11,11),0)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(img_gaus, cmap='gray')\n",
    "\n",
    "    ###Threshold pour enlever le background###\n",
    "    ret,img_thresh = cv2.threshold(img_gaus, 190, 200, cv2.THRESH_BINARY)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(img_thresh)\n",
    "\n",
    "    ###Dilate pour bien représenter les contours###\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    img_dilate = cv2.dilate(img_thresh, kernel, iterations = 1)\n",
    "    #plt.figure()\n",
    "    #plt.imshow(img_dilate)\n",
    "\n",
    "    ###Canny pour isoler les contours###\n",
    "    img_can = cv2.Canny(img_dilate,75,150)\n",
    "     #plt.figure()\n",
    "     #plt.imshow(img_can)\n",
    "\n",
    "    ###Trouver les contours###\n",
    "    contours, hierarchy = cv2.findContours(img_can,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    ###Dessiner les rectangles et les centres###\n",
    "    for i in range(0,len(contours)):\n",
    "        rec = cv2.minAreaRect(contours[i])\n",
    "        x,y = rec[0]\n",
    "        w,h = rec[1]\n",
    "        theta = repositionnementAngle(w,h,rec[2])\n",
    "        type_vis = typeVis(rec[1])\n",
    "        \n",
    "        if w > (4*h) or h > (4*w):\n",
    "            cv2.drawContours(img, contours, i, (255, 10, 0), 1)\n",
    "            cv2.circle(img, (int(x), int(y)), 3, (0,0,255),-1) \n",
    "            box = cv2.boxPoints(rec)\n",
    "            box = np.int0(box)\n",
    "            cv2.drawContours(img, [box], 0, (0,255,0), 2)\n",
    "            \n",
    "            vis.append((type_vis,x,y,theta))\n",
    "       \n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformationRepere(vis_cal):\n",
    "    P_t = np.linalg.inv(P)\n",
    "    \n",
    "    #projection en m selon l'axe z\n",
    "    d = 1/0.282 \n",
    "\n",
    "    x_s = np.array([vis_cal[1],vis_cal[2],1,d])\n",
    "    x_s_conv = x_s/x_s[3]\n",
    "    p_conv = np.dot(P_t, x_s_conv)\n",
    "    vis_info.append((vis_cal[0],p_conv[0],p_conv[1],p_conv[2],vis_cal[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportCSV(vis_info):\n",
    "    item_info = pd.DataFrame(vis_info, index=range(len(vis_info)), \n",
    "                             columns=['Type', 'X (m)', 'Y (m)', 'Z (m)', 'Theta (rad)'])\n",
    "    item_info.index.name='id'\n",
    "    item_info.to_csv(f'output/{filename}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Programme principal###\n",
    "index = 1\n",
    "\n",
    "for img in images: \n",
    "    filename = 'image_' + str(index)\n",
    "    index += 1\n",
    "    vis = list()\n",
    "    vis_info = list()\n",
    "    \n",
    "    isolationDesContours(img)\n",
    "    \n",
    "    for vis_cal in vis :\n",
    "        transformationRepere(vis_cal)\n",
    "    \n",
    "    exportCSV(vis_info)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse du résultat \n",
    "\n",
    "Les faiblesses de notre programme sont concentrées sur le rectangle autour des vis détectées. Ce dernier n'est pas dans la direction optimale qui suit la figure de la vis. La vis devrait être bien alignée dans l'encadrement. Dans notre cas, la pointe se retrouve souvent dans un coin du rectangle. Pour optimiser le résultat, il faudrait que la pointe de la vis se retrouve au milieu du côté de la boite.\n",
    "\n",
    "Une autre faiblesse provient des encadrés qui ne détectent pas nécessairement la pointe. La pointe est cachée par les filtres qui sont ajoutés pour  enlever l'arrière plan. Cela signifie que les filtres sont très précis et puissants, mais ils cachent des pointes de vis qui sont trop petites et les confondent avec l'arrière-plan. \n",
    "\n",
    "Malgré ces quelques faiblesses, notre code répond à toutes les exigences pour résoudre la problématique. La détection, l'isolation et le classement des vis ce fait sans soucie et les informations sont traduites dans des documents CSV. La détection ne contient pas d'abération visible et ce dans les neuf images qui ont été fourni pour l'analyse. Les cas particuliers sont gérés. Par exemple, deux vis très rapprochées ou une vis qui serait majoritairement à l'extérieur de l'image seraient éliminé par le pipeline de traitement. \n",
    "\n",
    "On peut en conclure que ce code pourrait être utilisé comme preuve de concept pour le triage de la quincaillerie par vision.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Aucun(e)",
  "colab": {
   "collapsed_sections": [],
   "name": "prob.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
